}
#Concatenate
data <- rbind(data,raw_file)
}
raw_data <- as.data.frame(data)
colnames(raw_data)
sum(raw_data$Lymphocytes == TRUE)
tmp <- raw_data[raw_data$Lymphocytes == TRUE,]
View(as.data.frame(tmp$`SSC-A`))
library(cyCONDOR)
library(flowWorkspace)
library(CytoML)
library(Biobase)
library(ggplot2)
library(dplyr)
ws <- CytoML::open_flowjo_xml("../.test_files/flowjo_workspace.wsp")
ws
gs <- CytoML::flowjo_to_gatingset(ws, name = "samples", path = "../.test_files/fcs_flowjo_ws/")
gs
flowWorkspace::plot(gs, bool = TRUE)
flowWorkspace::gs_pop_get_stats(gs)
data_gs = gs
inverse.transform = TRUE
transformation = "auto_logi"
remove_param = c("Time")
#get node list
gate_list <- flowWorkspace::gs_get_pop_paths(data_gs, path = "auto")
fs <- flowWorkspace::gs_pop_get_data(obj = data_gs, y = "root", inverse.transform = inverse.transform) %>% flowWorkspace::cytoset_to_flowSet()
filenames <- rownames(fs@phenoData)
num_files <- length(fs)
data <- NULL
for (single_file in 1:num_files){
raw_file <- exprs(fs[[single_file]])
#Fixup column names
colnames(raw_file) <- fs[[single_file]]@parameters$desc
colnames(raw_file)[which(is.na(colnames(raw_file)) | colnames(raw_file)== " ")] <- fs[[single_file]]@parameters$name[which(is.na(colnames(raw_file)) | colnames(raw_file)== " ")]
fs[[single_file]]@parameters$desc <- colnames(raw_file)
#Add file label
raw_file <- cbind(raw_file,rep(single_file,dim(raw_file)[1]))
colnames(raw_file)[dim(raw_file)[2]] <- "InFile"
# Add the gating info
for (gate in gate_list) {
raw_file <- cbind(raw_file, gh_pop_get_indices(gs[[single_file]], y = gate))
colnames(raw_file)[dim(raw_file)[2]] <- gate
}
#Concatenate
data <- rbind(data,raw_file)
}
raw_data <- as.data.frame(data)
colnames(raw_data)
tmp <- raw_data[raw_data$`CD19+` == TRUE, ]
dim(tmp)
View(tmp)
prep_fcd_new <- function(data_path,
max_cell,
useCSV = FALSE,
transformation = NULL,
remove_param = NULL,
anno_table,
filename_col,
seed = 91,
separator_anno = ",",
separator_fc_csv = ",",
simple_names = TRUE,
truncate_max_range = FALSE,
emptyValue = TRUE,
ignore.text.offset = FALSE,
verbose = FALSE) {
# Set seed for reproducibility
set.seed(seed)
if (verbose) {
print("Start reading the data")
}
## Load the data
data <- read_data_new(data_path = data_path,
max_cells = max_cell,
useCSV = useCSV,
separator = separator_fc_csv,
simple_names = simple_names,
truncate_max_range = truncate_max_range,
emptyValue = emptyValue,
ignore.text.offset = ignore.text.offset,
verbose = verbose)
raw_data <- as.matrix(data$merged_df) # Take the dataframe with the intensity values
## Add InFile to remove_param
remove_param <- c(remove_param, "InFile")
## Data Transformation
keep <- colnames(raw_data)[!colnames(raw_data) %in% remove_param]
raw_data <- raw_data[,which(colnames(raw_data) %in% keep)]
## Check if transformation parameter is provided
if(!is.null(transformation)){
## Check if transformation is a valid value
if (!transformation %in% c("clr", "arcsinh", "auto_logi", "none")) {
stop(paste0(transformation, " is not a valid transformation method"))
}
}else{stop("transformation parameter needs to be specified to run this function")}
if (verbose) {
print("Start transforming the data")
}
trans_data <- transform_data_new(keep = keep, transformation = transformation, original_data = raw_data, verbose = verbose)
## Clean the dataframe
df <- cbind(trans_data, expfcs_filename=data$merged_df[,"InFile"])
df <- as.data.frame(df)
df$expfcs_filename <- as.factor(df$expfcs_filename)
df$expfcs_filename <- factor(df$expfcs_filename, labels = data$data_files)
## Now add the annotation (as csv file)
anno <- read.delim(anno_table, sep = separator_anno)
df <- merge(df, anno, by.x = "expfcs_filename", by.y = filename_col)
## Give the unique rownames
rownames(df) <- paste(df$expfcs_filename, rownames(df), sep = "_")
## Prepare the final object
fcd <- list()
fcd[["expr"]][["orig"]] <- df[ ,colnames(df) %in% keep]
fcd[["anno"]][["cell_anno"]] <- df[ ,!colnames(df) %in% keep]
#save import parameters
fcd[["extras"]][["prep_param"]] <- list(data_path = data_path,
max_cell = max_cell,
transformation = transformation,
remove_param= remove_param,
anno_table = anno_table,
filename_col= filename_col,
seed= seed,
separator_anno = separator_anno,
separator_fc_csv = separator_fc_csv,
prep_function = "prep_fcd")
class(fcd) <- "flow_cytometry_dataframe"
return(fcd)
}
read_data_new <- function(data_path,
max_cells,
useCSV,
separator,
simple_names = TRUE,
truncate_max_range = FALSE,
emptyValue = TRUE,
ignore.text.offset = FALSE,
verbose = FALSE){
if(useCSV == FALSE){
# Read FCS files
data_files <- list.files(path = data_path, pattern = ".fcs")
merged_df <- NULL
for(FileNum in 1:length(data_files)){
if (verbose == TRUE) {
print(paste0("Loading file ", FileNum, " out of ", length(data_files)))
}
flow_frame_single <- read.FCS(paste0(data_path,"/",data_files[FileNum]),
transformation =F,
ignore.text.offset=ignore.text.offset,
truncate_max_range=truncate_max_range,
emptyValue = emptyValue)
single_file_red <- exprs(flow_frame_single)
## Downsample if needed
if (nrow(single_file_red)<=max_cells)
single_file_red <- single_file_red
else
single_file_red <- single_file_red[sample(nrow(single_file_red),max_cells,replace=F),]
#Adjust colnames
if (simple_names == TRUE) {
colnames(single_file_red) <- flow_frame_single@parameters@data$desc
colnames(single_file_red)[which(is.na(colnames(single_file_red)) | colnames(single_file_red)== " ")] <- flow_frame_single@parameters@data$name[which(is.na(colnames(single_file_red)) | colnames(single_file_red)== " ")]
} else {
colnames(single_file_red) <- ifelse(is.na(flow_frame_single@parameters@data$desc),
flow_frame_single@parameters@data$name,
paste0(flow_frame_single@parameters@data$name, "_", flow_frame_single@parameters@data$desc))
}
#Include column with file label for tracking and later merging annotation
single_file_red <- cbind(single_file_red,rep(FileNum,dim(single_file_red)[1]))
colnames(single_file_red)[dim(single_file_red)[2]] <- "InFile"
#Merge into a single data.frame
merged_df <- rbind(merged_df,single_file_red)
}
} else {
data_files <- list.files(path = data_path, pattern="*.csv")
csvdata <- lapply(paste0(data_path,"//",data_files),function(x) read.delim(x, check.names = F, sep = separator))
num_files <- length(csvdata)
merged_df <- NULL
for (single_file in 1:num_files){
single_file_red <- csvdata[[single_file]]
## Downsample if needed
if (nrow(single_file_red)<=max_cells)
single_file_red <- single_file_red
else
single_file_red <- single_file_red[sample(nrow(single_file_red),max_cells,replace=F),]
single_file_red <- cbind(single_file_red,rep(single_file,dim(single_file_red)[1]))
colnames(single_file_red)[dim(single_file_red)[2]] <- "InFile"
#Merge
merged_df <- rbind(merged_df,single_file_red)
}
}
return(list(merged_df=merged_df, data_files = data_files))
}
transform_data_new <- function(keep, transformation, original_data, verbose){
# Save temp df
transf_data <- original_data
# Transform the data
for(paramName in as.character(keep)){
if(transformation == "clr" ){
dataNum <- which(colnames(original_data)==paramName)
temp <- apply(original_data[,dataNum,drop=F],2, clr)
transf_data[,dataNum] <- temp
}
if(transformation == "arcsinh" ){
dataNum <- which(colnames(original_data)==paramName)
temp <- original_data[,dataNum,drop=F] / 5
temp <- asinh(temp)
transf_data[,dataNum] <- temp
}
if(transformation == "auto_logi"){
q<-0.05
m<-4.5
d <- original_data[,paramName]
w <- 0
t <- max(d)
nd <- d[d < 0]
nThres <- quantile(nd, 0.25) - 1.5 * IQR(nd)
nd <- nd[nd >= nThres]
if (length(nd)) {
r <- .Machine$double.eps + quantile(nd, q)
if (10^m * abs(r) <= t) {
w <- 0
}
else {
w <- (m - log10(t/abs(r)))/2
if (is.nan(w) || w > 2) {
warning(paste0("autoLgcl failed for channel: ",
paramName, "; using default fluor logicle transformation!"))
w <- 0.1
t <- 500000
m <- 4.5
}
}
}
templgcl <- logicleTransform(w=w, t=t, m=4.5, a=0)
dataNum <- which(colnames(original_data)==paramName)
temp <- apply(original_data[,dataNum,drop=F],2, templgcl)
transf_data[,dataNum] <- temp
if (verbose == TRUE) {
print(paste0(paramName, " w= ",w," t= ",t))
}
}
}
return(transf_data)
}
FCSpath <- "/home/user/data/Data/Figure 7 - Clinical Classifier/data_and_envs/CytoDX/train/"
data_path <- "/home/user/data/Data/Figure 7 - Clinical Classifier/data_and_envs/CytoDX/train/"
max_cells <- 20
useCSV <- FALSE
separator <- ","
library(flowCore)
set.seed(91)
old <- read_data(FCSpath = FCSpath, max_cells = max_cells, useCSV = useCSV, separator = separator)
FCSpath <- "/home/user/data/Data/Package/condor/.test_files/fcs/"
max_cells <- 20
useCSV <- FALSE
separator <- ","
library(flowCore)
set.seed(91)
old <- read_data(FCSpath = FCSpath, max_cells = max_cells, useCSV = useCSV, separator = separator)
old$merged_df[,"InFiles"]
old$merged_df[,"InFile"]
class(old$merged_df[,"InFile"])
as.factor(old$merged_df[,"InFile"])
raw_data <- old$merged_df
remove_param <- c(remove_param, "InFile")
transformation = "auto_logi"
remove_param = c("FSC-H", "SSC-H", "FSC-W", "SSC-W", "Time", "live_dead")
## Data Transformation
keep <- colnames(raw_data)[!colnames(raw_data) %in% remove_param]
keep
raw_data <- raw_data[,which(colnames(raw_data) %in% keep)]
raw_data
trans_data <- transform_data_new(keep = keep, transformation = transformation, original_data = raw_data, verbose = verbose)
verbose = TRUE
trans_data <- transform_data_new(keep = keep, transformation = transformation, original_data = raw_data, verbose = verbose)
## Clean the dataframe
df <- cbind(trans_data, expfcs_filename=data$merged_df[,"InFile"])
## Clean the dataframe
df <- cbind(trans_data, expfcs_filename=data$merged_df[,"InFile"])
data <- old
## Clean the dataframe
df <- cbind(trans_data, expfcs_filename=data$merged_df[,"InFile"])
class(df)
df <- as.data.frame(df)
df$expfcs_filename
class(df$expfcs_filename)
df$expfcs_filename <- as.factor(df$expfcs_filename)
df$expfcs_filename
df$expfcs_filename <- factor(df$expfcs_filename, labels = data$data_files)
library(cyCONDOR)
condor <- prep_fcd(data_path = "../.test_files/fcs/",
max_cell = 1000000000000000,
useCSV = FALSE,
transformation = "auto_logi",
remove_param = c("FSC-H", "SSC-H", "FSC-W", "SSC-W", "Time"),
anno_table = "../.test_files/metadata.csv",
filename_col = "filename"
)
class(condor)
table(condor$anno$cell_anno$expfcs_filename)
tmp <- flowCore::read.FCS("./.test_files/fcs/ID1.fcs")
tmp <- dim(flowCore::read.FCS("./.test_files/fcs/ID1.fcs")@expr)
dim(flowCore::read.FCS("./.test_files/fcs/ID1.fcs")@expr)
dim(flowCore::read.FCS("./.test_files/fcs/ID1.fcs", truncate_max_range = F)@exprs)
table(condor$anno$cell_anno$expfcs_filename)
dim(flowCore::read.FCS("./.test_files/fcs/ID2.fcs", truncate_max_range = F)@exprs)
dim(flowCore::read.FCS("./.test_files/fcs/ID10.fcs", truncate_max_range = F)@exprs)
dim(flowCore::read.FCS("./.test_files/fcs/ID5.fcs", truncate_max_range = F)@exprs)
dim(flowCore::read.FCS("./.test_files/fcs/ID9.fcs", truncate_max_range = F)@exprs)
dim(flowCore::read.FCS("./.test_files/fcs/ID8.fcs", truncate_max_range = F)@exprs)
table(condor$anno$cell_anno$expfcs_filename, condor$anno$cell_anno$group)
table(condor$anno$cell_anno$expfcs_filename, condor$anno$cell_anno$batch)
prep_fcd_new <- function(data_path,
max_cell,
useCSV = FALSE,
transformation = NULL,
remove_param = NULL,
anno_table,
filename_col,
seed = 91,
separator_anno = ",",
separator_fc_csv = ",",
simple_names = TRUE,
truncate_max_range = FALSE,
emptyValue = TRUE,
ignore.text.offset = FALSE,
verbose = FALSE) {
# Set seed for reproducibility
set.seed(seed)
if (verbose) {
print("Start reading the data")
}
## Load the data
data <- read_data_new(data_path = data_path,
max_cells = max_cell,
useCSV = useCSV,
separator = separator_fc_csv,
simple_names = simple_names,
truncate_max_range = truncate_max_range,
emptyValue = emptyValue,
ignore.text.offset = ignore.text.offset,
verbose = verbose)
raw_data <- as.matrix(data$merged_df) # Take the dataframe with the intensity values
## Add InFile to remove_param
remove_param <- c(remove_param, "InFile")
## Data Transformation
keep <- colnames(raw_data)[!colnames(raw_data) %in% remove_param]
raw_data <- raw_data[,which(colnames(raw_data) %in% keep)]
## Check if transformation parameter is provided
if(!is.null(transformation)){
## Check if transformation is a valid value
if (!transformation %in% c("clr", "arcsinh", "auto_logi", "none")) {
stop(paste0(transformation, " is not a valid transformation method"))
}
}else{stop("transformation parameter needs to be specified to run this function")}
if (verbose) {
print("Start transforming the data")
}
trans_data <- transform_data_new(keep = keep, transformation = transformation, original_data = raw_data, verbose = verbose)
## Clean the dataframe
df <- cbind(trans_data, expfcs_filename=data$merged_df[,"InFile"])
df <- as.data.frame(df)
df$expfcs_filename <- as.factor(df$expfcs_filename)
df$expfcs_filename <- factor(df$expfcs_filename, labels = data$data_files)
## Now add the annotation (as csv file)
anno <- read.delim(anno_table, sep = separator_anno)
df <- merge(df, anno, by.x = "expfcs_filename", by.y = filename_col)
## Give the unique rownames
rownames(df) <- paste(df$expfcs_filename, rownames(df), sep = "_")
## Prepare the final object
fcd <- list()
fcd[["expr"]][["orig"]] <- df[ ,colnames(df) %in% keep]
fcd[["anno"]][["cell_anno"]] <- df[ ,!colnames(df) %in% keep]
#save import parameters
fcd[["extras"]][["prep_param"]] <- list(data_path = data_path,
max_cell = max_cell,
transformation = transformation,
remove_param= remove_param,
anno_table = anno_table,
filename_col= filename_col,
seed= seed,
separator_anno = separator_anno,
separator_fc_csv = separator_fc_csv,
prep_function = "prep_fcd")
class(fcd) <- "flow_cytometry_dataframe"
return(fcd)
}
read_data_new <- function(data_path,
max_cells,
useCSV,
separator,
simple_names = TRUE,
truncate_max_range = FALSE,
emptyValue = TRUE,
ignore.text.offset = FALSE,
verbose = FALSE){
if(useCSV == FALSE){
# Read FCS files
data_files <- list.files(path = data_path, pattern = ".fcs")
merged_df <- NULL
for(FileNum in 1:length(data_files)){
if (verbose == TRUE) {
print(paste0("Loading file ", FileNum, " out of ", length(data_files)))
}
flow_frame_single <- read.FCS(paste0(data_path,"/",data_files[FileNum]),
transformation =F,
ignore.text.offset=ignore.text.offset,
truncate_max_range=truncate_max_range,
emptyValue = emptyValue)
single_file_red <- exprs(flow_frame_single)
## Downsample if needed
if (nrow(single_file_red)<=max_cells)
single_file_red <- single_file_red
else
single_file_red <- single_file_red[sample(nrow(single_file_red),max_cells,replace=F),]
#Adjust colnames
if (simple_names == TRUE) {
colnames(single_file_red) <- flow_frame_single@parameters@data$desc
colnames(single_file_red)[which(is.na(colnames(single_file_red)) | colnames(single_file_red)== " ")] <- flow_frame_single@parameters@data$name[which(is.na(colnames(single_file_red)) | colnames(single_file_red)== " ")]
} else {
colnames(single_file_red) <- ifelse(is.na(flow_frame_single@parameters@data$desc),
flow_frame_single@parameters@data$name,
paste0(flow_frame_single@parameters@data$name, "_", flow_frame_single@parameters@data$desc))
}
#Include column with file label for tracking and later merging annotation
single_file_red <- cbind(single_file_red,rep(FileNum,dim(single_file_red)[1]))
colnames(single_file_red)[dim(single_file_red)[2]] <- "InFile"
#Merge into a single data.frame
merged_df <- rbind(merged_df,single_file_red)
}
} else {
data_files <- list.files(path = data_path, pattern="*.csv")
csvdata <- lapply(paste0(data_path,"//",data_files),function(x) read.delim(x, check.names = F, sep = separator))
num_files <- length(csvdata)
merged_df <- NULL
for (single_file in 1:num_files){
single_file_red <- csvdata[[single_file]]
## Downsample if needed
if (nrow(single_file_red)<=max_cells)
single_file_red <- single_file_red
else
single_file_red <- single_file_red[sample(nrow(single_file_red),max_cells,replace=F),]
single_file_red <- cbind(single_file_red,rep(single_file,dim(single_file_red)[1]))
colnames(single_file_red)[dim(single_file_red)[2]] <- "InFile"
#Merge
merged_df <- rbind(merged_df,single_file_red)
}
}
return(list(merged_df=merged_df, data_files = data_files))
}
transform_data_new <- function(keep, transformation, original_data, verbose){
# Save temp df
transf_data <- original_data
# Transform the data
for(paramName in as.character(keep)){
if(transformation == "clr" ){
dataNum <- which(colnames(original_data)==paramName)
temp <- apply(original_data[,dataNum,drop=F],2, clr)
transf_data[,dataNum] <- temp
}
if(transformation == "arcsinh" ){
dataNum <- which(colnames(original_data)==paramName)
temp <- original_data[,dataNum,drop=F] / 5
temp <- asinh(temp)
transf_data[,dataNum] <- temp
}
if(transformation == "auto_logi"){
q<-0.05
m<-4.5
d <- original_data[,paramName]
w <- 0
t <- max(d)
nd <- d[d < 0]
nThres <- quantile(nd, 0.25) - 1.5 * IQR(nd)
nd <- nd[nd >= nThres]
if (length(nd)) {
r <- .Machine$double.eps + quantile(nd, q)
if (10^m * abs(r) <= t) {
w <- 0
}
else {
w <- (m - log10(t/abs(r)))/2
if (is.nan(w) || w > 2) {
warning(paste0("autoLgcl failed for channel: ",
paramName, "; using default fluor logicle transformation!"))
w <- 0.1
t <- 500000
m <- 4.5
}
}
}
templgcl <- logicleTransform(w=w, t=t, m=4.5, a=0)
dataNum <- which(colnames(original_data)==paramName)
temp <- apply(original_data[,dataNum,drop=F],2, templgcl)
transf_data[,dataNum] <- temp
if (verbose == TRUE) {
print(paste0(paramName, " w= ",w," t= ",t))
}
}
}
return(transf_data)
}
condor <- prep_fcd_new(data_path = "/home/user/data/Data/Figure 2 - Example Workflow/data/FC/",
max_cell = 10000000000000000,
useCSV = FALSE,
transformation = "auto_logi",
remove_param = c("FSC-H", "SSC-H", "FSC-W", "SSC-W", "Time", "live_dead"),
anno_table = "/home/user/data/Data/Figure 2 - Example Workflow/data/FC_metadata.csv",
filename_col = "filename",
seed = 91,
verbose = TRUE)
table(condor$anno$cell_anno$expfcs_filename, condor$anno$cell_anno$group)
dim(flowCore::read.FCS("./.test_files/fcs/ID8.fcs", truncate_max_range = F)@exprs)
